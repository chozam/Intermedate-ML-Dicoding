# -*- coding: utf-8 -*-
"""EuroSat-img-classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a65KPCK8Tk7wIbXZrk4bzjTmvJZaYIrV

# **Euro Satelit Image Classification**
"""

! pip install kaggle

from google.colab import drive
drive.mount('/content/gdrive')

import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/My Drive/Kaggle"

! kaggle datasets download -d apollo2506/eurosat-dataset

import zipfile, os
local_zip = 'eurosat-dataset.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

os.listdir('/content/EuroSAT')

os.remove('/content/EuroSAT/train.csv')
os.remove('/content/EuroSAT/test.csv')
os.remove('/content/EuroSAT/validation.csv')
os.remove('/content/EuroSAT/label_map.json')
os.listdir('/content/EuroSAT')

for i in range(0, len(os.listdir('/content/EuroSAT'))):
  label = os.listdir('/content/EuroSAT')[i]
  print(f"{label} = {len(os.listdir(f'/content/EuroSAT/{label}'))}")

os.listdir('/content/EuroSAT/AnnualCrop')

import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
img = image.load_img('/content/EuroSAT/AnnualCrop/AnnualCrop_418.jpg')
imgplot = plt.imshow(img)

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

base_dir = '/content/EuroSAT/'
train_datagen = ImageDataGenerator(
    rescale=1./255,
    horizontal_flip=True,
    vertical_flip=True,
    rotation_range=0.2,
    brightness_range = (0.5, 1.5),
    zoom_range=0.2,
    validation_split=0.2
    )

val_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
    )

train_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(64, 64),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)
val_generator = val_datagen.flow_from_directory(
    base_dir,
    target_size=(64, 64),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(64, 64, 3)),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

model.summary()

from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint

class MyCallback(Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_accuracy')>0.94) and (logs.get('accuracy')>0.94):
      self.model.stop_training = True
model_cp = ModelCheckpoint(
    filepath="/tmp/best-weights/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5",
    monitor="val_accuracy",
    verbose=1,
    save_best_only=True,
    mode="max"
)
callback = MyCallback()
early_stopping = EarlyStopping(monitor='val_accuracy', patience=20)

model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

history = model.fit(
    train_generator,
    steps_per_epoch=128,
    epochs=100,
    validation_data=val_generator,
    validation_steps=100,
    verbose=1,
    callbacks=[callback, model_cp, early_stopping]
)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Akurasi Model')
plt.ylabel('Accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

import matplotlib.pyplot as plt
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('Loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper right')
plt.show()

val_loss_acc = model.evaluate(val_generator, steps=len(val_generator))

"""### **Export TF Lite**"""

import pathlib
# Menyimpan model dalam format SavedModel
export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)

# Convert SavedModel menjadi vegs.tflite
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('euro.tflite')
tflite_model_file.write_bytes(tflite_model)

tflite_model_size = len(tflite_model) / (1024 * 1024)
print(f'TFLite model size = {tflite_model_size} MBs.')